{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Price prediction\n",
    "\n",
    "<img src=\"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/screen-shot-2020-05-15-at-9-06-38-am-1589548150.png?resize=980:*\"/>\n",
    "\n",
    "## Прогнозирование стоимости автомобиля по характеристикам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начнем с Baseline. В нем уже реализовано следующее:\n",
    "* Построена \"наивную\"/baseline модель, предсказывающая цену по модели и году выпуска (для сравнения с другими моделями)\n",
    "* Обработаны и отнормированы признаки\n",
    "* Сделана первая модель на основе градиентного бустинга с помощью CatBoost\n",
    "* Сделана вторая модель на основе нейронных сетей\n",
    "* Сделана multi-input нейронная сеть для анализа табличных данных и текста одновременно\n",
    "* В multi-input сеть добавлена обработка изображений\n",
    "* Ансамблирование градиентного бустинга и нейронной сети (усреднение их предсказаний)\n",
    "\n",
    "## Что попробуем еще:\n",
    "* Управление LR и другие оптимизаторы\n",
    "* Сокращение размерности категориальных признаков\n",
    "* Обработка текста - лемматизация и аугментация\n",
    "\n",
    "## Лог изменений:\n",
    "* Version 1 - Подбор параметров с помощью GridSearchCV\n",
    "* Versions 2,3 - Поиск и заполнение пропусков, обработка признака vehicleConfiguration\n",
    "* Version 4 - Попробовал логарифмировать признаки mileage, modelDate и productionDate. Улучшения MAPE Это не дало, даже немного ухудшило показатель.Также в этой версии попробовал различные оптимизаторы для model 3 - Лучше Adam никто не справился. Возможно потому что не пробовал их более тонко настраивать.\n",
    "* Version 5 - Сделал лемматизацию признака Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:05:39.666350Z",
     "iopub.status.busy": "2021-09-09T08:05:39.665987Z",
     "iopub.status.idle": "2021-09-09T08:05:47.496860Z",
     "shell.execute_reply": "2021-09-09T08:05:47.496036Z",
     "shell.execute_reply.started": "2021-09-09T08:05:39.666317Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:05:47.499328Z",
     "iopub.status.busy": "2021-09-09T08:05:47.499035Z",
     "iopub.status.idle": "2021-09-09T08:05:53.581576Z",
     "shell.execute_reply": "2021-09-09T08:05:53.580709Z",
     "shell.execute_reply.started": "2021-09-09T08:05:47.499299Z"
    }
   },
   "outputs": [],
   "source": [
    "#аугментации изображений\n",
    "!pip install albumentations -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:05:53.583550Z",
     "iopub.status.busy": "2021-09-09T08:05:53.583211Z",
     "iopub.status.idle": "2021-09-09T08:06:05.409000Z",
     "shell.execute_reply": "2021-09-09T08:06:05.408039Z",
     "shell.execute_reply.started": "2021-09-09T08:05:53.583512Z"
    }
   },
   "outputs": [],
   "source": [
    "#Инструменты для работы с текстом - вариант с nltk. Пока не работает.\n",
    "!pip install nltk\n",
    "!pip install pymystem3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:05.410895Z",
     "iopub.status.busy": "2021-09-09T08:06:05.410546Z",
     "iopub.status.idle": "2021-09-09T08:06:12.149086Z",
     "shell.execute_reply": "2021-09-09T08:06:12.148315Z",
     "shell.execute_reply.started": "2021-09-09T08:06:05.410854Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import sys\n",
    "import PIL\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import missingno as msno\n",
    "\n",
    "# # keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import albumentations\n",
    "\n",
    "#lemmatization\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "\n",
    "# plt\n",
    "import matplotlib.pyplot as plt\n",
    "#увеличим дефолтный размер графиков\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "#графики в svg выглядят более четкими\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:12.152629Z",
     "iopub.status.busy": "2021-09-09T08:06:12.152275Z",
     "iopub.status.idle": "2021-09-09T08:06:12.164550Z",
     "shell.execute_reply": "2021-09-09T08:06:12.161084Z",
     "shell.execute_reply.started": "2021-09-09T08:06:12.152594Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Python       :', sys.version.split('\\n')[0])\n",
    "print('Numpy        :', np.__version__)\n",
    "print('Tensorflow   :', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:12.168339Z",
     "iopub.status.busy": "2021-09-09T08:06:12.167952Z",
     "iopub.status.idle": "2021-09-09T08:06:12.173264Z",
     "shell.execute_reply": "2021-09-09T08:06:12.172234Z",
     "shell.execute_reply.started": "2021-09-09T08:06:12.168300Z"
    }
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:12.175490Z",
     "iopub.status.busy": "2021-09-09T08:06:12.174998Z",
     "iopub.status.idle": "2021-09-09T08:06:12.182496Z",
     "shell.execute_reply": "2021-09-09T08:06:12.181544Z",
     "shell.execute_reply.started": "2021-09-09T08:06:12.175451Z"
    }
   },
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:12.184407Z",
     "iopub.status.busy": "2021-09-09T08:06:12.183922Z",
     "iopub.status.idle": "2021-09-09T08:06:14.447131Z",
     "shell.execute_reply": "2021-09-09T08:06:14.445994Z",
     "shell.execute_reply.started": "2021-09-09T08:06:12.184368Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на типы признаков:\n",
    "\n",
    "* bodyType - категориальный\n",
    "* brand - категориальный\n",
    "* color - категориальный\n",
    "* description - текстовый\n",
    "* engineDisplacement - числовой, представленный как текст\n",
    "* enginePower - числовой, представленный как текст\n",
    "* fuelType - категориальный\n",
    "* mileage - числовой\n",
    "* modelDate - числовой\n",
    "* model_info - категориальный\n",
    "* name - категориальный, желательно сократить размерность\n",
    "* numberOfDoors - категориальный\n",
    "* price - числовой, целевой\n",
    "* productionDate - числовой\n",
    "* sell_id - изображение (файл доступен по адресу, основанному на sell_id)\n",
    "* vehicleConfiguration - не используется (комбинация других столбцов)\n",
    "* vehicleTransmission - категориальный\n",
    "* Владельцы - категориальный\n",
    "* Владение - числовой, представленный как текст\n",
    "* ПТС - категориальный\n",
    "* Привод - категориальный\n",
    "* Руль - категориальный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:14.449340Z",
     "iopub.status.busy": "2021-09-09T08:06:14.448932Z",
     "iopub.status.idle": "2021-09-09T08:06:14.857671Z",
     "shell.execute_reply": "2021-09-09T08:06:14.856578Z",
     "shell.execute_reply.started": "2021-09-09T08:06:14.449295Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../input/sf-dst-car-price-prediction-part2/'\n",
    "train = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:14.862809Z",
     "iopub.status.busy": "2021-09-09T08:06:14.862434Z",
     "iopub.status.idle": "2021-09-09T08:06:14.906633Z",
     "shell.execute_reply": "2021-09-09T08:06:14.905823Z",
     "shell.execute_reply.started": "2021-09-09T08:06:14.862772Z"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:14.912764Z",
     "iopub.status.busy": "2021-09-09T08:06:14.910608Z",
     "iopub.status.idle": "2021-09-09T08:06:15.014880Z",
     "shell.execute_reply": "2021-09-09T08:06:15.013908Z",
     "shell.execute_reply.started": "2021-09-09T08:06:14.912724Z"
    }
   },
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Создадим \"наивную\" модель \n",
    "Эта модель будет предсказывать среднюю цену по модели и году выпуска. \n",
    "C ней будем сравнивать другие модели.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:15.020850Z",
     "iopub.status.busy": "2021-09-09T08:06:15.018739Z",
     "iopub.status.idle": "2021-09-09T08:06:15.034946Z",
     "shell.execute_reply": "2021-09-09T08:06:15.034079Z",
     "shell.execute_reply.started": "2021-09-09T08:06:15.020808Z"
    }
   },
   "outputs": [],
   "source": [
    "# split данных\n",
    "data_train, data_test = train_test_split(train, test_size=0.15, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:15.040995Z",
     "iopub.status.busy": "2021-09-09T08:06:15.038797Z",
     "iopub.status.idle": "2021-09-09T08:06:18.976277Z",
     "shell.execute_reply": "2021-09-09T08:06:18.974369Z",
     "shell.execute_reply.started": "2021-09-09T08:06:15.040946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Наивная модель\n",
    "predicts = []\n",
    "for index, row in pd.DataFrame(data_test[['model_info', 'productionDate']]).iterrows():\n",
    "    query = f\"model_info == '{row[0]}' and productionDate == '{row[1]}'\"\n",
    "    predicts.append(data_train.query(query)['price'].median())\n",
    "\n",
    "# заполним не найденные совпадения\n",
    "predicts = pd.DataFrame(predicts)\n",
    "predicts = predicts.fillna(predicts.median())\n",
    "\n",
    "# округлим\n",
    "predicts = (predicts // 1000) * 1000\n",
    "\n",
    "#оцениваем точность\n",
    "print(f\"Точность наивной модели по метрике MAPE: {(mape(data_test['price'], predicts.values[:, 0]))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем быстрый анализ данных для того, чтобы понимать, сможет ли с этими данными работать наш алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядят распределения числовых признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:18.979086Z",
     "iopub.status.busy": "2021-09-09T08:06:18.978710Z",
     "iopub.status.idle": "2021-09-09T08:06:19.676067Z",
     "shell.execute_reply": "2021-09-09T08:06:19.675112Z",
     "shell.execute_reply.started": "2021-09-09T08:06:18.979046Z"
    }
   },
   "outputs": [],
   "source": [
    "#посмотрим, как выглядят распределения числовых признаков\n",
    "def visualize_distributions(titles_values_dict):\n",
    "  columns = min(3, len(titles_values_dict))\n",
    "  rows = (len(titles_values_dict) - 1) // columns + 1\n",
    "  fig = plt.figure(figsize = (columns * 6, rows * 4))\n",
    "  for i, (title, values) in enumerate(titles_values_dict.items()):\n",
    "    hist, bins = np.histogram(values, bins = 20)\n",
    "    ax = fig.add_subplot(rows, columns, i + 1)\n",
    "    ax.bar(bins[:-1], hist, width = (bins[1] - bins[0]) * 0.7)\n",
    "    ax.set_title(title)\n",
    "  plt.show()\n",
    "\n",
    "visualize_distributions({\n",
    "    'mileage': train['mileage'].dropna(),\n",
    "    'modelDate': train['modelDate'].dropna(),\n",
    "    'productionDate': train['productionDate'].dropna()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на те же самые признаки, но с логарифмированием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:19.678322Z",
     "iopub.status.busy": "2021-09-09T08:06:19.677666Z",
     "iopub.status.idle": "2021-09-09T08:06:20.186001Z",
     "shell.execute_reply": "2021-09-09T08:06:20.184849Z",
     "shell.execute_reply.started": "2021-09-09T08:06:19.678272Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_distributions({\n",
    "    'mileage': np.log(train['mileage'].dropna()),\n",
    "    'modelDate': np.log(train['modelDate'].dropna()),\n",
    "    'productionDate': np.log(train['productionDate'].dropna())\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого:\n",
    "* CatBoost сможет работать с признаками и в таком виде, но для нейросети нужны нормированные данные.\n",
    "* Имеет смысл попробовать логарифмировать признаки mileage, modelDate и producrionDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProc Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:20.187943Z",
     "iopub.status.busy": "2021-09-09T08:06:20.187569Z",
     "iopub.status.idle": "2021-09-09T08:06:20.194179Z",
     "shell.execute_reply": "2021-09-09T08:06:20.192958Z",
     "shell.execute_reply.started": "2021-09-09T08:06:20.187904Z"
    }
   },
   "outputs": [],
   "source": [
    "#используем все текстовые признаки как категориальные без предобработки (я намеренно не включил name, потому что мы его убираем)\n",
    "categorical_features = ['bodyType', 'brand', 'color', 'engineDisplacement', 'enginePower', 'fuelType', 'model_info',\n",
    "  'numberOfDoors', 'vehicleTransmission', 'Владельцы', 'Владение', 'ПТС', 'Привод', 'Руль']\n",
    "\n",
    "#используем все числовые признаки\n",
    "numerical_features = ['mileage', 'modelDate', 'productionDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:20.196255Z",
     "iopub.status.busy": "2021-09-09T08:06:20.195704Z",
     "iopub.status.idle": "2021-09-09T08:06:20.219850Z",
     "shell.execute_reply": "2021-09-09T08:06:20.218966Z",
     "shell.execute_reply.started": "2021-09-09T08:06:20.196207Z"
    }
   },
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "train['sample'] = 1 # помечаем где у нас трейн\n",
    "test['sample'] = 0 # помечаем где у нас тест\n",
    "test['price'] = 0 # в тесте у нас нет значения price, мы его должны предсказать, поэтому пока просто заполняем нулями\n",
    "\n",
    "data = test.append(train, sort=False).reset_index(drop=True) # объединяем\n",
    "print(train.shape, test.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выше - это baseline. Однако нам еще нужно разобраться с пропусками, попробовать выделить дополнительные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:20.221766Z",
     "iopub.status.busy": "2021-09-09T08:06:20.221362Z",
     "iopub.status.idle": "2021-09-09T08:06:20.590801Z",
     "shell.execute_reply": "2021-09-09T08:06:20.589889Z",
     "shell.execute_reply.started": "2021-09-09T08:06:20.221725Z"
    }
   },
   "outputs": [],
   "source": [
    "display(msno.matrix(data))\n",
    "display(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски у нас есть только признаке \"Владение\" (во \"Владельцы\" единственный пропуск заполним как \"Неизвестно\", этот код будет в функции preproc).  \n",
    "Поскольку у нас нет информации о дате последней регистрации, то как вычислить этот признак - пока не знаю. Можно вместо NaN заполнить его просто как \"Нет информации\"\n",
    "\n",
    "Взглянем на интересный признак, который пока не обработан - vehicleConfiguration. Это отличный признак, обозначающий тип кузова авто. Очистим его и добавим к остальным категориальным признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:20.592259Z",
     "iopub.status.busy": "2021-09-09T08:06:20.591898Z",
     "iopub.status.idle": "2021-09-09T08:06:20.611675Z",
     "shell.execute_reply": "2021-09-09T08:06:20.610766Z",
     "shell.execute_reply.started": "2021-09-09T08:06:20.592220Z"
    }
   },
   "outputs": [],
   "source": [
    "# Посмотрим на признак vehicleConfiguration. Он вполне себе \n",
    "\n",
    "data['vehicleConfiguration'] = data['vehicleConfiguration'].apply(lambda x:x.partition(' ')[0])\n",
    "data['vehicleConfiguration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:20.613237Z",
     "iopub.status.busy": "2021-09-09T08:06:20.612878Z",
     "iopub.status.idle": "2021-09-09T08:06:20.616934Z",
     "shell.execute_reply": "2021-09-09T08:06:20.616101Z",
     "shell.execute_reply.started": "2021-09-09T08:06:20.613201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Выглядит пристойно. Добавим этот признак к категориальным.\n",
    "\n",
    "categorical_features.append('vehicleConfiguration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:20.618909Z",
     "iopub.status.busy": "2021-09-09T08:06:20.618444Z",
     "iopub.status.idle": "2021-09-09T08:06:25.399799Z",
     "shell.execute_reply": "2021-09-09T08:06:25.398969Z",
     "shell.execute_reply.started": "2021-09-09T08:06:20.618871Z"
    }
   },
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### 1. Предобработка ############################################################## \n",
    "    # убираем не нужные для модели признаки\n",
    "    df_output.drop(['description','sell_id'], axis = 1, inplace=True)\n",
    "    df_output.drop(['name'], axis = 1, inplace=True)\n",
    "    \n",
    "    # ################### Numerical Features ############################################################## \n",
    "    # Далее заполняем пропуски\n",
    "    for column in numerical_features:\n",
    "        df_output[column].fillna(df_output[column].median(), inplace=True)\n",
    "    # тут ваш код по обработке NAN\n",
    "    df_output['Владельцы'].fillna('Неизвестно')\n",
    "    df_output['Владельцы'].fillna('Нет информации')\n",
    "    \n",
    "    # Логарифмирование данных\n",
    "    #df_output['modelDate'] = np.log(df_output['modelDate'])\n",
    "    #df_output['mileage'] = np.log(df_output['mileage'])\n",
    "    #df_output['productionDate'] = np.log(df_output['productionDate'])\n",
    "    \n",
    "    \n",
    "    # Нормализация данных\n",
    "    scaler = MinMaxScaler()\n",
    "    for column in numerical_features:\n",
    "        df_output[column] = scaler.fit_transform(df_output[[column]])[:,0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ################### Categorical Features ############################################################## \n",
    "    # Label Encoding\n",
    "    for column in categorical_features:\n",
    "        df_output[column] = df_output[column].astype('category').cat.codes\n",
    "        \n",
    "    # One-Hot Encoding: в pandas есть готовая функция - get_dummies.\n",
    "    df_output = pd.get_dummies(df_output, columns=categorical_features, dummy_na=False)\n",
    "    # тут ваш код не Encoding фитчей\n",
    "    # ....\n",
    "    \n",
    "    \n",
    "    # ################### Feature Engineering ####################################################\n",
    "    # тут ваш код не генерацию новых фитчей\n",
    "    # ....\n",
    "    \n",
    "    \n",
    "    # ################### Clean #################################################### \n",
    "    \n",
    "    return df_output\n",
    "\n",
    "# Предобработка текста\n",
    "\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "# Lemmatization function\n",
    "def preproc_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:06:25.401733Z",
     "iopub.status.busy": "2021-09-09T08:06:25.401314Z",
     "iopub.status.idle": "2021-09-09T08:07:16.022355Z",
     "shell.execute_reply": "2021-09-09T08:07:16.021439Z",
     "shell.execute_reply.started": "2021-09-09T08:06:25.401686Z"
    }
   },
   "outputs": [],
   "source": [
    "# Сразу сделаем лемматизацию признака description\n",
    "data['description'] = data['description'].apply(lambda x:preproc_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:16.024663Z",
     "iopub.status.busy": "2021-09-09T08:07:16.024054Z",
     "iopub.status.idle": "2021-09-09T08:07:16.129405Z",
     "shell.execute_reply": "2021-09-09T08:07:16.128461Z",
     "shell.execute_reply.started": "2021-09-09T08:07:16.024620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Запускаем алгоритмы для предобработки и проверяем, что получилось\n",
    "df_preproc = preproc_data(data)\n",
    "df_preproc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:16.131630Z",
     "iopub.status.busy": "2021-09-09T08:07:16.131235Z",
     "iopub.status.idle": "2021-09-09T08:07:16.163661Z",
     "shell.execute_reply": "2021-09-09T08:07:16.162838Z",
     "shell.execute_reply.started": "2021-09-09T08:07:16.131592Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:16.165717Z",
     "iopub.status.busy": "2021-09-09T08:07:16.165264Z",
     "iopub.status.idle": "2021-09-09T08:07:16.226151Z",
     "shell.execute_reply": "2021-09-09T08:07:16.225465Z",
     "shell.execute_reply.started": "2021-09-09T08:07:16.165673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.price.values     # наш таргет\n",
    "X = train_data.drop(['price'], axis=1)\n",
    "X_sub = test_data.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:16.227931Z",
     "iopub.status.busy": "2021-09-09T08:07:16.227587Z",
     "iopub.status.idle": "2021-09-09T08:07:16.435640Z",
     "shell.execute_reply": "2021-09-09T08:07:16.434644Z",
     "shell.execute_reply.started": "2021-09-09T08:07:16.227894Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь впервые попробуем применить инструмент для автоматического поиска оптимального learning rate. \n",
    "\n",
    "Я пробовал перебирать вручную, и лучших значений удалось достичь при LR=0.03. Но для более тонкого подбора уже необходимо использовать что-то автоматическое.\n",
    "Сразу напрашивается GridSearch. \n",
    "\n",
    "Попробовал пройтись по значениям Learning Rate c шагом 0.01 до 0.05 и с шагом от 0.05 до 0.98. Лучший результат был в при значении 0.088 - MAPE получилось 12,87%.\n",
    "Код подбора LR закомментирован, чтобы не отнимать время каждый раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:16.438131Z",
     "iopub.status.busy": "2021-09-09T08:07:16.437503Z",
     "iopub.status.idle": "2021-09-09T08:07:16.454627Z",
     "shell.execute_reply": "2021-09-09T08:07:16.453942Z",
     "shell.execute_reply.started": "2021-09-09T08:07:16.438076Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:16.456463Z",
     "iopub.status.busy": "2021-09-09T08:07:16.456073Z",
     "iopub.status.idle": "2021-09-09T08:07:48.613069Z",
     "shell.execute_reply": "2021-09-09T08:07:48.612155Z",
     "shell.execute_reply.started": "2021-09-09T08:07:16.456425Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations = 5000,\n",
    "                          #depth=10,\n",
    "                          learning_rate = 0.088,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['RMSE', 'MAE'],\n",
    "                          od_wait=500,\n",
    "                          #task_type='GPU',\n",
    "                         )\n",
    "model.fit(X_train, y_train,\n",
    "        eval_set=(X_test, y_test),\n",
    "        verbose_eval=100,\n",
    "        use_best_model=True,\n",
    "       #plot=True\n",
    "        )\n",
    "\n",
    "# Создаем список для поиска оптимального learning Rate\n",
    "# step=0.002\n",
    "# rate=0.05\n",
    "# lr_range=[]\n",
    "# while rate<=0.098:\n",
    "#    lr_range.append(rate)\n",
    "#    rate += step\n",
    "    \n",
    "\n",
    "# param_grid = dict(learning_rate=lr_range)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "# opt_model = grid.fit(X_train, y_train)\n",
    "\n",
    "result = model.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best: %f using %s\" % (opt_model.best_score_, opt_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:48.614740Z",
     "iopub.status.busy": "2021-09-09T08:07:48.614403Z",
     "iopub.status.idle": "2021-09-09T08:07:48.644606Z",
     "shell.execute_reply": "2021-09-09T08:07:48.643554Z",
     "shell.execute_reply.started": "2021-09-09T08:07:48.614703Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predict_catboost = result.predict(X_test)\n",
    "print(f\"TEST mape: {(mape(y_test, test_predict_catboost))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-09T08:07:48.646555Z",
     "iopub.status.busy": "2021-09-09T08:07:48.646175Z",
     "iopub.status.idle": "2021-09-09T08:07:49.001663Z",
     "shell.execute_reply": "2021-09-09T08:07:49.000811Z",
     "shell.execute_reply.started": "2021-09-09T08:07:48.646511Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_predict_catboost = model.predict(X_sub)\n",
    "sample_submission['price'] = sub_predict_catboost\n",
    "sample_submission.to_csv('catboost_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Tabular NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим обычную сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:05.121513Z",
     "iopub.status.busy": "2021-09-08T19:09:05.121168Z",
     "iopub.status.idle": "2021-09-08T19:09:05.149246Z",
     "shell.execute_reply": "2021-09-08T19:09:05.14858Z",
     "shell.execute_reply.started": "2021-09-08T19:09:05.121479Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Dense NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:05.154875Z",
     "iopub.status.busy": "2021-09-08T19:09:05.154635Z",
     "iopub.status.idle": "2021-09-08T19:09:07.275199Z",
     "shell.execute_reply": "2021-09-08T19:09:07.274213Z",
     "shell.execute_reply.started": "2021-09-08T19:09:05.154851Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(256, activation=\"relu\"))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:07.276889Z",
     "iopub.status.busy": "2021-09-08T19:09:07.276525Z",
     "iopub.status.idle": "2021-09-08T19:09:07.28691Z",
     "shell.execute_reply": "2021-09-08T19:09:07.284713Z",
     "shell.execute_reply.started": "2021-09-08T19:09:07.276851Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:07.2894Z",
     "iopub.status.busy": "2021-09-08T19:09:07.288781Z",
     "iopub.status.idle": "2021-09-08T19:09:07.306052Z",
     "shell.execute_reply": "2021-09-08T19:09:07.305356Z",
     "shell.execute_reply.started": "2021-09-08T19:09:07.289359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:07.308252Z",
     "iopub.status.busy": "2021-09-08T19:09:07.307602Z",
     "iopub.status.idle": "2021-09-08T19:09:07.314567Z",
     "shell.execute_reply": "2021-09-08T19:09:07.313313Z",
     "shell.execute_reply.started": "2021-09-08T19:09:07.308211Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/best_model.hdf5' , monitor=['val_MAPE'], verbose=0  , mode='min')\n",
    "earlystop = EarlyStopping(monitor='val_MAPE', patience=50, restore_best_weights=True,)\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:07.316417Z",
     "iopub.status.busy": "2021-09-08T19:09:07.316003Z",
     "iopub.status.idle": "2021-09-08T19:09:58.724981Z",
     "shell.execute_reply": "2021-09-08T19:09:58.724113Z",
     "shell.execute_reply.started": "2021-09-08T19:09:07.316379Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=callbacks_list,\n",
    "                    verbose=0,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:58.726766Z",
     "iopub.status.busy": "2021-09-08T19:09:58.726405Z",
     "iopub.status.idle": "2021-09-08T19:09:58.856518Z",
     "shell.execute_reply": "2021-09-08T19:09:58.855609Z",
     "shell.execute_reply.started": "2021-09-08T19:09:58.72673Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['MAPE'], label='train')\n",
    "plt.plot(history.history['val_MAPE'], label='test')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:58.858721Z",
     "iopub.status.busy": "2021-09-08T19:09:58.858244Z",
     "iopub.status.idle": "2021-09-08T19:09:58.895369Z",
     "shell.execute_reply": "2021-09-08T19:09:58.894666Z",
     "shell.execute_reply.started": "2021-09-08T19:09:58.85868Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('../working/best_model.hdf5')\n",
    "model.save('../working/nn_1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:58.897197Z",
     "iopub.status.busy": "2021-09-08T19:09:58.896706Z",
     "iopub.status.idle": "2021-09-08T19:09:59.039332Z",
     "shell.execute_reply": "2021-09-08T19:09:59.038489Z",
     "shell.execute_reply.started": "2021-09-08T19:09:58.897159Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predict_nn1 = model.predict(X_test)\n",
    "print(f\"TEST mape: {(mape(y_test, test_predict_nn1[:,0]))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:59.042916Z",
     "iopub.status.busy": "2021-09-08T19:09:59.042651Z",
     "iopub.status.idle": "2021-09-08T19:09:59.142947Z",
     "shell.execute_reply": "2021-09-08T19:09:59.14218Z",
     "shell.execute_reply.started": "2021-09-08T19:09:59.04289Z"
    }
   },
   "outputs": [],
   "source": [
    "#sub_predict_nn1 = model.predict(X_sub)\n",
    "#sample_submission['price'] = sub_predict_nn1[:,0]\n",
    "#sample_submission.to_csv('nn1_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендации для улучшения Model 3:    \n",
    "* В нейросеть желательно подавать данные с распределением, близким к нормальному, поэтому от некоторых числовых признаков имеет смысл взять логарифм перед нормализацией. Пример:\n",
    "`modelDateNorm = np.log(2020 - data['modelDate'])`\n",
    "Статья по теме: https://habr.com/ru/company/ods/blog/325422\n",
    "\n",
    "* Извлечение числовых значений из текста:\n",
    "Парсинг признаков 'engineDisplacement', 'enginePower', 'Владение' для извлечения числовых значений.\n",
    "\n",
    "* Cокращение размерности категориальных признаков\n",
    "Признак name 'name' содержит данные, которые уже есть в других столбцах ('enginePower', 'engineDisplacement', 'vehicleTransmission'), поэтому эти данные можно удалить. Затем следует еще сильнее сократить размерность, например, выделив наличие xDrive в качестве отдельного признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: NLP + Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:59.146385Z",
     "iopub.status.busy": "2021-09-08T19:09:59.146083Z",
     "iopub.status.idle": "2021-09-08T19:09:59.15617Z",
     "shell.execute_reply": "2021-09-08T19:09:59.154498Z",
     "shell.execute_reply.started": "2021-09-08T19:09:59.146358Z"
    }
   },
   "outputs": [],
   "source": [
    "data.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:59.158079Z",
     "iopub.status.busy": "2021-09-08T19:09:59.157606Z",
     "iopub.status.idle": "2021-09-08T19:09:59.162195Z",
     "shell.execute_reply": "2021-09-08T19:09:59.161105Z",
     "shell.execute_reply.started": "2021-09-08T19:09:59.158042Z"
    }
   },
   "outputs": [],
   "source": [
    "# TOKENIZER\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_WORDS = 100000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:59.164469Z",
     "iopub.status.busy": "2021-09-08T19:09:59.164068Z",
     "iopub.status.idle": "2021-09-08T19:09:59.173316Z",
     "shell.execute_reply": "2021-09-08T19:09:59.172552Z",
     "shell.execute_reply.started": "2021-09-08T19:09:59.164432Z"
    }
   },
   "outputs": [],
   "source": [
    "# split данных\n",
    "text_train = data.description.iloc[X_train.index]\n",
    "text_test = data.description.iloc[X_test.index]\n",
    "text_sub = data.description.iloc[X_sub.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:09:59.175406Z",
     "iopub.status.busy": "2021-09-08T19:09:59.17492Z",
     "iopub.status.idle": "2021-09-08T19:10:00.388981Z",
     "shell.execute_reply": "2021-09-08T19:10:00.388049Z",
     "shell.execute_reply.started": "2021-09-08T19:09:59.175325Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenize = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenize.fit_on_texts(data.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:00.390965Z",
     "iopub.status.busy": "2021-09-08T19:10:00.390599Z",
     "iopub.status.idle": "2021-09-08T19:10:00.43106Z",
     "shell.execute_reply": "2021-09-08T19:10:00.430229Z",
     "shell.execute_reply.started": "2021-09-08T19:10:00.390925Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenize.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:00.433102Z",
     "iopub.status.busy": "2021-09-08T19:10:00.432721Z",
     "iopub.status.idle": "2021-09-08T19:10:01.95331Z",
     "shell.execute_reply": "2021-09-08T19:10:01.95227Z",
     "shell.execute_reply.started": "2021-09-08T19:10:00.433061Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "text_train_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_train), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "text_test_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_test), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "text_sub_sequences = sequence.pad_sequences(tokenize.texts_to_sequences(text_sub), maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(text_train_sequences.shape, text_test_sequences.shape, text_sub_sequences.shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:01.954987Z",
     "iopub.status.busy": "2021-09-08T19:10:01.954623Z",
     "iopub.status.idle": "2021-09-08T19:10:01.963376Z",
     "shell.execute_reply": "2021-09-08T19:10:01.962251Z",
     "shell.execute_reply.started": "2021-09-08T19:10:01.954948Z"
    }
   },
   "outputs": [],
   "source": [
    "# вот так теперь выглядит наш текст\n",
    "print(text_train.iloc[6])\n",
    "print(text_train_sequences[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:01.965468Z",
     "iopub.status.busy": "2021-09-08T19:10:01.964742Z",
     "iopub.status.idle": "2021-09-08T19:10:02.487216Z",
     "shell.execute_reply": "2021-09-08T19:10:02.486343Z",
     "shell.execute_reply.started": "2021-09-08T19:10:01.965429Z"
    }
   },
   "outputs": [],
   "source": [
    "model_nlp = Sequential()\n",
    "model_nlp.add(L.Input(shape=MAX_SEQUENCE_LENGTH, name=\"seq_description\"))\n",
    "model_nlp.add(L.Embedding(len(tokenize.word_index)+1, MAX_SEQUENCE_LENGTH,))\n",
    "model_nlp.add(L.LSTM(256, return_sequences=True))\n",
    "model_nlp.add(L.Dropout(0.5))\n",
    "model_nlp.add(L.LSTM(128,))\n",
    "model_nlp.add(L.Dropout(0.25))\n",
    "model_nlp.add(L.Dense(64, activation=\"relu\"))\n",
    "model_nlp.add(L.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:02.488861Z",
     "iopub.status.busy": "2021-09-08T19:10:02.488511Z",
     "iopub.status.idle": "2021-09-08T19:10:02.529053Z",
     "shell.execute_reply": "2021-09-08T19:10:02.528387Z",
     "shell.execute_reply.started": "2021-09-08T19:10:02.488827Z"
    }
   },
   "outputs": [],
   "source": [
    "model_mlp = Sequential()\n",
    "model_mlp.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model_mlp.add(L.Dropout(0.5))\n",
    "model_mlp.add(L.Dense(256, activation=\"relu\"))\n",
    "model_mlp.add(L.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Inputs NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:02.531418Z",
     "iopub.status.busy": "2021-09-08T19:10:02.530918Z",
     "iopub.status.idle": "2021-09-08T19:10:02.559307Z",
     "shell.execute_reply": "2021-09-08T19:10:02.558666Z",
     "shell.execute_reply.started": "2021-09-08T19:10:02.53138Z"
    }
   },
   "outputs": [],
   "source": [
    "combinedInput = L.concatenate([model_nlp.output, model_mlp.output])\n",
    "# being our regression head\n",
    "head = L.Dense(64, activation=\"relu\")(combinedInput)\n",
    "head = L.Dense(1, activation=\"linear\")(head)\n",
    "\n",
    "model = Model(inputs=[model_nlp.input, model_mlp.input], outputs=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:02.560819Z",
     "iopub.status.busy": "2021-09-08T19:10:02.560479Z",
     "iopub.status.idle": "2021-09-08T19:10:02.574068Z",
     "shell.execute_reply": "2021-09-08T19:10:02.573279Z",
     "shell.execute_reply.started": "2021-09-08T19:10:02.560784Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:02.576422Z",
     "iopub.status.busy": "2021-09-08T19:10:02.576077Z",
     "iopub.status.idle": "2021-09-08T19:10:02.590996Z",
     "shell.execute_reply": "2021-09-08T19:10:02.589941Z",
     "shell.execute_reply.started": "2021-09-08T19:10:02.576385Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:02.592995Z",
     "iopub.status.busy": "2021-09-08T19:10:02.592402Z",
     "iopub.status.idle": "2021-09-08T19:10:02.599026Z",
     "shell.execute_reply": "2021-09-08T19:10:02.59801Z",
     "shell.execute_reply.started": "2021-09-08T19:10:02.592954Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\n",
    "earlystop = EarlyStopping(monitor='val_MAPE', patience=10, restore_best_weights=True,)\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-09-08T19:10:02.60066Z",
     "iopub.status.busy": "2021-09-08T19:10:02.600252Z",
     "iopub.status.idle": "2021-09-08T19:14:57.42172Z",
     "shell.execute_reply": "2021-09-08T19:14:57.420994Z",
     "shell.execute_reply.started": "2021-09-08T19:10:02.600625Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit([text_train_sequences, X_train], y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n",
    "                    validation_data=([text_test_sequences, X_test], y_test),\n",
    "                    callbacks=callbacks_list\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:14:57.42468Z",
     "iopub.status.busy": "2021-09-08T19:14:57.424071Z",
     "iopub.status.idle": "2021-09-08T19:14:57.543859Z",
     "shell.execute_reply": "2021-09-08T19:14:57.543011Z",
     "shell.execute_reply.started": "2021-09-08T19:14:57.424639Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['MAPE'], label='train')\n",
    "plt.plot(history.history['val_MAPE'], label='test')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:14:57.54583Z",
     "iopub.status.busy": "2021-09-08T19:14:57.545473Z",
     "iopub.status.idle": "2021-09-08T19:14:57.788496Z",
     "shell.execute_reply": "2021-09-08T19:14:57.787491Z",
     "shell.execute_reply.started": "2021-09-08T19:14:57.545794Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights('../working/best_model.hdf5')\n",
    "model.save('../working/nn_mlp_nlp.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:14:57.790454Z",
     "iopub.status.busy": "2021-09-08T19:14:57.78998Z",
     "iopub.status.idle": "2021-09-08T19:14:58.939027Z",
     "shell.execute_reply": "2021-09-08T19:14:58.937259Z",
     "shell.execute_reply.started": "2021-09-08T19:14:57.790406Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predict_nn2 = model.predict([text_test_sequences, X_test])\n",
    "print(f\"TEST mape: {(mape(y_test, test_predict_nn2[:,0]))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T19:14:58.94246Z",
     "iopub.status.busy": "2021-09-08T19:14:58.942194Z",
     "iopub.status.idle": "2021-09-08T19:14:59.737992Z",
     "shell.execute_reply": "2021-09-08T19:14:59.737099Z",
     "shell.execute_reply.started": "2021-09-08T19:14:58.942433Z"
    }
   },
   "outputs": [],
   "source": [
    "#sub_predict_nn2 = model.predict([text_sub_sequences, X_sub])\n",
    "#sample_submission['price'] = sub_predict_nn2[:,0]\n",
    "#sample_submission.to_csv('nn2_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идеи для улучшения NLP части:\n",
    "* Выделить из описаний часто встречающиеся блоки текста, заменив их на кодовые слова или удалив\n",
    "* Сделать предобработку текста, например, сделать лемматизацию - алгоритм ставящий все слова в форму по умолчанию (глаголы в инфинитив и т. д.), чтобы токенайзер не преобразовывал разные формы слова в разные числа\n",
    "Статья по теме: https://habr.com/ru/company/Voximplant/blog/446738/\n",
    "* Поработать над алгоритмами очистки и аугментации текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Добавляем картинки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убедимся, что цены и фото подгрузились верно\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "random_image = train.sample(n = 9)\n",
    "random_image_paths = random_image['sell_id'].values\n",
    "random_image_cat = random_image['price'].values\n",
    "\n",
    "for index, path in enumerate(random_image_paths):\n",
    "    im = PIL.Image.open(DATA_DIR+'img/img/' + str(path) + '.jpg')\n",
    "    plt.subplot(3, 3, index + 1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('price: ' + str(random_image_cat[index]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (320, 240)\n",
    "\n",
    "def get_image_array(index):\n",
    "    images_train = []\n",
    "    for index, sell_id in enumerate(data['sell_id'].iloc[index].values):\n",
    "        image = cv2.imread(DATA_DIR + 'img/img/' + str(sell_id) + '.jpg')\n",
    "        assert(image is not None)\n",
    "        image = cv2.resize(image, size)\n",
    "        images_train.append(image)\n",
    "    images_train = np.array(images_train)\n",
    "    print('images shape', images_train.shape, 'dtype', images_train.dtype)\n",
    "    return(images_train)\n",
    "\n",
    "images_train = get_image_array(X_train.index)\n",
    "images_test = get_image_array(X_test.index)\n",
    "images_sub = get_image_array(X_sub.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
    ")\n",
    "\n",
    "\n",
    "#пример взят из официальной документации: https://albumentations.readthedocs.io/en/latest/examples.html\n",
    "augmentation = Compose([\n",
    "    HorizontalFlip(),\n",
    "    OneOf([\n",
    "        IAAAdditiveGaussianNoise(),\n",
    "        GaussNoise(),\n",
    "    ], p=0.2),\n",
    "    OneOf([\n",
    "        MotionBlur(p=0.2),\n",
    "        MedianBlur(blur_limit=3, p=0.1),\n",
    "        Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2),\n",
    "    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=15, p=1),\n",
    "    OneOf([\n",
    "        OpticalDistortion(p=0.3),\n",
    "        GridDistortion(p=0.1),\n",
    "        IAAPiecewiseAffine(p=0.3),\n",
    "    ], p=0.2),\n",
    "    OneOf([\n",
    "        CLAHE(clip_limit=2),\n",
    "        IAASharpen(),\n",
    "        IAAEmboss(),\n",
    "        RandomBrightnessContrast(),\n",
    "    ], p=0.3),\n",
    "    HueSaturationValue(p=0.3),\n",
    "], p=1)\n",
    "\n",
    "#пример\n",
    "plt.figure(figsize = (12,8))\n",
    "for i in range(9):\n",
    "    img = augmentation(image = images_train[0])['image']\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_augmentations(images):\n",
    "  print('применение аугментаций', end = '')\n",
    "  augmented_images = np.empty(images.shape)\n",
    "  for i in range(images.shape[0]):\n",
    "    if i % 200 == 0:\n",
    "      print('.', end = '')\n",
    "    augment_dict = augmentation(image = images[i])\n",
    "    augmented_image = augment_dict['image']\n",
    "    augmented_images[i] = augmented_image\n",
    "  print('')\n",
    "  return augmented_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data.Dataset\n",
    "Если все изображения мы будем хранить в памяти, то может возникнуть проблема ее нехватки. Не храните все изображения в памяти целиком!\n",
    "\n",
    "Метод .fit() модели keras может принимать либо данные в виде массивов или тензоров, либо разного рода итераторы, из которых наиболее современным и гибким является [tf.data.Dataset](https://www.tensorflow.org/guide/data). Он представляет собой конвейер, то есть мы указываем, откуда берем данные и какую цепочку преобразований с ними выполняем. Далее мы будем работать с tf.data.Dataset.\n",
    "\n",
    "Dataset хранит информацию о конечном или бесконечном наборе кортежей (tuple) с данными и может возвращать эти наборы по очереди. Например, данными могут быть пары (input, target) для обучения нейросети. С данными можно осуществлять преобразования, которые осуществляются по мере необходимости ([lazy evaluation](https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BD%D0%B8%D0%B2%D1%8B%D0%B5_%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F)).\n",
    "\n",
    "`tf.data.Dataset.from_tensor_slices(data)` - создает датасет из данных, которые представляют собой либо массив, либо кортеж из массивов. Деление осуществляется по первому индексу каждого массива. Например, если `data = (np.zeros((128, 256, 256)), np.zeros(128))`, то датасет будет содержать 128 элементов, каждый из которых содержит один массив 256x256 и одно число.\n",
    "\n",
    "`dataset2 = dataset1.map(func)` - применение функции к датасету; функция должна принимать столько аргументов, каков размер кортежа в датасете 1 и возвращать столько, сколько нужно иметь в датасете 2. Пусть, например, датасет содержит изображения и метки, а нам нужно создать датасет только из изображений, тогда мы напишем так: `dataset2 = dataset.map(lambda img, label: img)`.\n",
    "\n",
    "`dataset2 = dataset1.batch(8)` - группировка по батчам; если датасет 2 должен вернуть один элемент, то он берет из датасета 1 восемь элементов, склеивает их (нулевой индекс результата - номер элемента) и возвращает.\n",
    "\n",
    "`dataset.__iter__()` - превращение датасета в итератор, из которого можно получать элементы методом `.__next__()`. Итератор, в отличие от самого датасета, хранит позицию текущего элемента. Можно также перебирать датасет циклом for.\n",
    "\n",
    "`dataset2 = dataset1.repeat(X)` - датасет 2 будет повторять датасет 1 X раз.\n",
    "\n",
    "Если нам нужно взять из датасета 1000 элементов и использовать их как тестовые, а остальные как обучающие, то мы напишем так:\n",
    "\n",
    "`test_dataset = dataset.take(1000)\n",
    "train_dataset = dataset.skip(1000)`\n",
    "\n",
    "Датасет по сути неизменен: такие операции, как map, batch, repeat, take, skip никак не затрагивают оригинальный датасет. Если датасет хранит элементы [1, 2, 3], то выполнив 3 раза подряд функцию dataset.take(1) мы получим 3 новых датасета, каждый из которых вернет число 1. Если же мы выполним функцию dataset.skip(1), мы получим датасет, возвращающий числа [2, 3], но исходный датасет все равно будет возвращать [1, 2, 3] каждый раз, когда мы его перебираем.\n",
    "\n",
    "tf.Dataset всегда выполняется в graph-режиме (в противоположность eager-режиму), поэтому либо преобразования (`.map()`) должны содержать только tensorflow-функции, либо мы должны использовать tf.py_function в качестве обертки для функций, вызываемых в `.map()`. Подробнее можно прочитать [здесь](https://www.tensorflow.org/guide/data#applying_arbitrary_python_logic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP part\n",
    "tokenize = Tokenizer(num_words=MAX_WORDS)\n",
    "tokenize.fit_on_texts(data.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    return augmentation(image = image.numpy())['image']\n",
    "\n",
    "def tokenize_(descriptions):\n",
    "  return sequence.pad_sequences(tokenize.texts_to_sequences(descriptions), maxlen = MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return tokenize_([text.numpy().decode('utf-8')])[0]\n",
    "\n",
    "def tf_process_train_dataset_element(image, table_data, text, price):\n",
    "    im_shape = image.shape\n",
    "    [image,] = tf.py_function(process_image, [image], [tf.uint8])\n",
    "    image.set_shape(im_shape)\n",
    "    [text,] = tf.py_function(tokenize_text, [text], [tf.int32])\n",
    "    return (image, table_data, text), price\n",
    "\n",
    "def tf_process_val_dataset_element(image, table_data, text, price):\n",
    "    [text,] = tf.py_function(tokenize_text, [text], [tf.int32])\n",
    "    return (image, table_data, text), price\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    images_train, X_train, data.description.iloc[X_train.index], y_train\n",
    "    )).map(tf_process_train_dataset_element)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    images_test, X_test, data.description.iloc[X_test.index], y_test\n",
    "    )).map(tf_process_val_dataset_element)\n",
    "\n",
    "y_sub = np.zeros(len(X_sub))\n",
    "sub_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    images_sub, X_sub, data.description.iloc[X_sub.index], y_sub\n",
    "    )).map(tf_process_val_dataset_element)\n",
    "\n",
    "#проверяем, что нет ошибок (не будет выброшено исключение):\n",
    "train_dataset.__iter__().__next__();\n",
    "test_dataset.__iter__().__next__();\n",
    "sub_dataset.__iter__().__next__();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим сверточную сеть для анализа изображений без \"головы\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#нормализация включена в состав модели EfficientNetB3, поэтому на вход она принимает данные типа uint8\n",
    "efficientnet_model = tf.keras.applications.efficientnet.EfficientNetB3(weights = 'imagenet', include_top = False, input_shape = (size[1], size[0], 3))\n",
    "efficientnet_output = L.GlobalAveragePooling2D()(efficientnet_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#строим нейросеть для анализа табличных данных\n",
    "tabular_model = Sequential([\n",
    "    L.Input(shape = X.shape[1]),\n",
    "    L.Dense(512, activation = 'relu'),\n",
    "    L.Dropout(0.5),\n",
    "    L.Dense(256, activation = 'relu'),\n",
    "    L.Dropout(0.5),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP\n",
    "nlp_model = Sequential([\n",
    "    L.Input(shape=MAX_SEQUENCE_LENGTH, name=\"seq_description\"),\n",
    "    L.Embedding(len(tokenize.word_index)+1, MAX_SEQUENCE_LENGTH,),\n",
    "    L.LSTM(256, return_sequences=True),\n",
    "    L.Dropout(0.5),\n",
    "    L.LSTM(128),\n",
    "    L.Dropout(0.25),\n",
    "    L.Dense(64),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "#объединяем выходы трех нейросетей\n",
    "combinedInput = L.concatenate([efficientnet_output, tabular_model.output, nlp_model.output])\n",
    "\n",
    "# being our regression head\n",
    "head = L.Dense(256, activation=\"relu\")(combinedInput)\n",
    "head = L.Dense(1,)(head)\n",
    "\n",
    "model = Model(inputs=[efficientnet_model.input, tabular_model.input, nlp_model.input], outputs=head)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.005)\n",
    "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../working/best_model.hdf5', monitor=['val_MAPE'], verbose=0, mode='min')\n",
    "earlystop = EarlyStopping(monitor='val_MAPE', patience=10, restore_best_weights=True,)\n",
    "callbacks_list = [checkpoint, earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset.batch(30),\n",
    "                    epochs=100,\n",
    "                    validation_data = test_dataset.batch(30),\n",
    "                    callbacks=callbacks_list\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['MAPE'], label='train')\n",
    "plt.plot(history.history['val_MAPE'], label='test')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../working/best_model.hdf5')\n",
    "model.save('../working/nn_final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_nn3 = model.predict(test_dataset.batch(30))\n",
    "print(f\"TEST mape: {(mape(y_test, test_predict_nn3[:,0]))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_predict_nn3 = model.predict(sub_dataset.batch(30))\n",
    "#sample_submission['price'] = sub_predict_nn3[:,0]\n",
    "#sample_submission.to_csv('nn3_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Общие рекомендации:\n",
    "* Попробовать разные архитектуры\n",
    "* Провести более детальный анализ результатов\n",
    "* Попробовать различные подходы в управление LR и оптимизаторы\n",
    "* Поработать с таргетом\n",
    "* Использовать Fine-tuning\n",
    "\n",
    "#### Tabular\n",
    "* В нейросеть желательно подавать данные с распределением, близким к нормальному, поэтому от некоторых числовых признаков имеет смысл взять логарифм перед нормализацией. Пример:\n",
    "`modelDateNorm = np.log(2020 - data['modelDate'])`\n",
    "Статья по теме: https://habr.com/ru/company/ods/blog/325422\n",
    "\n",
    "* Извлечение числовых значений из текста:\n",
    "Парсинг признаков 'engineDisplacement', 'enginePower', 'Владение' для извлечения числовых значений.\n",
    "\n",
    "* Cокращение размерности категориальных признаков\n",
    "Признак name 'name' содержит данные, которые уже есть в других столбцах ('enginePower', 'engineDisplacement', 'vehicleTransmission'). Можно удалить эти данные. Затем можно еще сильнее сократить размерность, например выделив наличие xDrive в качестве отдельного признака.\n",
    "\n",
    "* Поработать над Feature engineering\n",
    "\n",
    "\n",
    "\n",
    "#### NLP\n",
    "* Выделить из описаний часто встречающиеся блоки текста, заменив их на кодовые слова или удалив\n",
    "* Сделать предобработку текста, например сделать лемматизацию - алгоритм ставящий все слова в форму по умолчанию (глаголы в инфинитив и т. д.), чтобы токенайзер не преобразовывал разные формы слова в разные числа\n",
    "Статья по теме: https://habr.com/ru/company/Voximplant/blog/446738/\n",
    "* Поработать над алгоритмами очистки и аугментации текста\n",
    "\n",
    "\n",
    "\n",
    "#### CV\n",
    "* Попробовать различные аугментации\n",
    "* Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_predict = (test_predict_catboost + test_predict_nn3[:,0]) / 2\n",
    "print(f\"TEST mape: {(mape(y_test, blend_predict))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blend_sub_predict = (sub_predict_catboost + sub_predict_nn3[:,0]) / 2\n",
    "#sample_submission['price'] = blend_sub_predict\n",
    "#sample_submission.to_csv('blend_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Bonus: проброс признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "model_mlp = Sequential()\n",
    "model_mlp.add(L.Dense(512, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model_mlp.add(L.Dropout(0.5))\n",
    "model_mlp.add(L.Dense(256, activation=\"relu\"))\n",
    "model_mlp.add(L.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE Input\n",
    "# Iput\n",
    "productiondate = L.Input(shape=[1], name=\"productiondate\")\n",
    "# Embeddings layers\n",
    "emb_productiondate = L.Embedding(len(X.productionDate.unique().tolist())+1, 20)(productiondate)\n",
    "f_productiondate = L.Flatten()(emb_productiondate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedInput = L.concatenate([model_mlp.output, f_productiondate,])\n",
    "# being our regression head\n",
    "head = L.Dense(64, activation=\"relu\")(combinedInput)\n",
    "head = L.Dense(1, activation=\"linear\")(head)\n",
    "\n",
    "model = Model(inputs=[model_mlp.input, productiondate], outputs=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "model.compile(loss='MAPE',optimizer=optimizer, metrics=['MAPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([X_train, X_train.productionDate.values], y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=500, # фактически мы обучаем пока EarlyStopping не остановит обучение\n",
    "                    validation_data=([X_test, X_test.productionDate.values], y_test),\n",
    "                    callbacks=callbacks_list\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../working/best_model.hdf5')\n",
    "test_predict_nn_bonus = model.predict([X_test, X_test.productionDate.values])\n",
    "print(f\"TEST mape: {(mape(y_test, test_predict_nn_bonus[:,0]))*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоги и выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы я реализовал подбор параметров LR и Optimizer с помощью GridSearch, сделал дополнительную обработку некоторых признаков (в частности сделал лемматизацию для признака description и vehicleConfiguration).\n",
    "\n",
    "К сожалению, ни одно из решений не смогло повлиять на улучшение MAPE, итоговый результат получился хуже Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
